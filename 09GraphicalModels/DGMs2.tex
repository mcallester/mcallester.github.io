\input ../../SlidePreamble
\input ../../preamble

\begin{document}

{\Huge

  \centerline{\bf TTIC 31230, Fundamentals of Deep Learning}
  \bigskip
  \centerline{David McAllester, Autumn 2020}
  \vfill
  \vfill
  \centerline{\bf Exponential Softmax Backpropagation:}
  \vfill
  \centerline{\bf The Model Marginals}
\vfill
\vfill
\vfill

\slide{Notation}

$x$ is an input (e.g. an image).

\vfill
$\hat{\cal Y} [N]$ is any label for $x$ --- a vector $\hat{\cal Y}[0],\ldots,\hat{\cal Y}[N-1]$ with $\hat{\cal Y}[n]$ an integer in $\{1,\ldots,L\}$.

\vfill
For example $n$ might range over the pixels of an image and $\hat{\cal Y}[n]$ names a semantic label of pixel $n$.

\vfill
${\cal Y}[N]$ is the gold label for input $x$ --- the structured label assigned to $x$ in the training data.

\slide{Back-Propagation Through Exponential Softmax}

We have node and edge score tensors computed by a deep network.

$$s^N[N,L] = f^N_\Phi(x) \;\;\;\;\; s^E[E,L,L]  =  f^E_\Phi(x)$$

\vfill
\begin{eqnarray*}
{\color{red} s(\hat{\cal Y})} & = & \sum_n\;s^N[n,\hat{\cal Y}[n]] + \sum_{\tuple{n,m} \in \mathrm{Edges}}\;s^E[\tuple{n,m},\hat{\cal Y}[n],\;\hat{\cal Y}[m]] \\
\\
{\color{red} P_s(\hat{\cal Y})} & = & \softmax_{\hat{\cal Y}}\;s(\hat{\cal Y}) \;\;\mbox{\color{red} all possible $\hat{\cal Y}$} \\
\\
{\cal L} & = & {\color{red} - \ln P_s({\cal Y}) \;\;\;\mbox{gold label ${\cal Y}$}}
\end{eqnarray*}

\vfill
For SGD we want to compute {\color{red} $s^N.\grad[N,L]$} and {\color{red} $s^E.\grad[E,L,L]$}.


\slide{Model Marginals Theorem}

Theorem:
\begin{eqnarray*}
    s^N.\mathrm{grad}[n,\ell] & = &  {\color{red} P_{\hat{\cal Y} \sim P_s}(\;\;\hat{\cal Y}[n] = \ell\;\;)} \\
    & & \;\;\;\;\;- \bbone[\;\;{\cal Y}[n] = \ell\;\;] \\
    \\
    s^E.\mathrm{grad}[\tuple{n,m},\ell,\ell'] & = &  {\color{red} P_{\hat{\cal Y} \sim P_s}(\;\;\hat{\cal Y}[n] = \ell \; \wedge \; \hat{\cal Y}[m] = \ell'\;\;)} \\
    & & \;\;\;\;\;- \bbone[\;\;{\cal Y}[n] = \ell\; \wedge \; {\cal Y}[m] = \ell'\;\;]
\end{eqnarray*}

\vfill
We need to compute (or approximate) the model marginals.

\slide{Proof of Model Marginals Theorem}

We consider the case of node marginals, the case of edge marginals is similar.

{\huge
\begin{eqnarray*}
    s^N.\grad[n,\ell] & = & \partial {\cal L}(\Phi,x,{\cal Y})\;/\;\partial s^N[n,\ell] \\
    \\
    & = & \partial \left(-\ln \frac{1}{Z}\exp(s({\cal Y}))\right)\;/\;\partial s^N[n,\ell] \\
    \\
    & = & \partial (\ln Z - s({\cal Y}))\;/\;\partial s^N[n,\ell] \\
    \\
    & = & \left(\frac{1}{Z} \sum_{\hat{\cal Y}} e^{s(\hat{\cal Y})} \left(\partial s(\hat{\cal Y})/\partial s^N[n,\ell]\right)\right)
    - \left(\partial s({\cal Y}) /\partial s^N[n,\ell]\right) 
\end{eqnarray*}
}

\slide{Proof of Model Marginals Theorem}

{\huge
\begin{eqnarray*}
    s^N.\grad[n,\ell] & = & \left(\frac{1}{Z} \sum_{\hat{\cal Y}} e^{s(\hat{\cal Y})} \left(\partial s(\hat{\cal Y})/\partial s^N[n,\ell]\right)\right)
    - \left(\partial s({\cal Y}) /\partial s^N[n,\ell]\right)  \\
    \\
    & = & \left(\sum_{\hat{\cal Y}} P_s(\hat{\cal Y}) \left(\partial s(\hat{\cal Y})/\partial s^N[n,\ell]\right)\right)
    - \left(\partial s({\cal Y}) /\partial s^N[n,\ell]\right)    \\
    \\
    s(\hat{\cal Y}) & = & \sum_n\;s^N[n,\hat{\cal Y}[n]]\; + \sum_{\tuple{n,m} \in \mathrm{Edges}}\;s^E[\tuple{n,m},\hat{\cal Y}[n],\;\hat{\cal Y}[m]] \\
    \\
    \frac{\partial s(\hat{\cal Y})}{\partial s^N[n,\ell]} & = & \bbone[\hat{\cal Y}[n] = \ell]
\end{eqnarray*}
}

\slide{Proof of Model Marginals Theorem}

\huge{
\begin{eqnarray*}
    s^N.\grad[n,\ell] & = & \left(\frac{1}{Z} \sum_{\hat{\cal Y}} e^{s(\hat{\cal Y})} \left(\partial s(\hat{\cal Y})/\partial s^N[n,\ell]\right)\right)
    - \left(\partial s({\cal Y}) /\partial s^N[n,\ell]\right)  \\
    \\
    & & \left(\sum_{\hat{\cal Y}} P_s(\hat{\cal Y}) \left(\partial s(\hat{\cal Y})/\partial s^N[n,\ell]\right)\right)
    - \left(\partial s({\cal Y}) /\partial s^N[n,\ell]\right)    \\
    \\
    & = & E_{\hat{\cal Y} \sim P_s}\bbone[{\color{red} \hat{\cal Y}}[n] = \ell]
    - \bbone[{\color{red}{\cal Y}}[n] = \ell] \\
    \\
    & = & P_{\hat{\cal Y} \sim P_s}({\color{red} \hat{\cal Y}}[n] = \ell)
      - \bbone[{\color{red}{\cal Y}}[n] = \ell]
\end{eqnarray*}
}

\slide{Model Marginals Theorem}

Theorem:
\begin{eqnarray*}
    s^N.\mathrm{grad}[n,\ell] & = &   P_{\hat{\cal Y} \sim P_s}(\;\;{\color{red} \hat{\cal Y}}[n] = \ell\;\;) \\
    & & \;\;\;\;\;- \bbone[\;\;{\color{red} {\cal Y}}[n] = \ell\;\;] \\
    \\
    s^E.\mathrm{grad}[\tuple{n,m},\ell,\ell'] & = &  P_{\hat{\cal Y} \sim P_s}(\;\;{\color{red} \hat{\cal Y}}[n] = \ell \; \wedge \; {\color{red} \hat{\cal Y}}[m] = \ell'\;\;) \\
    & & \;\;\;\;\;- \bbone[\;\;{\color{red} {\cal Y}}[n] = \ell\; \wedge \; {\color{red} {\cal Y}}[m] = \ell'\;\;]
\end{eqnarray*}

\slide{END}

}

\end{document}
