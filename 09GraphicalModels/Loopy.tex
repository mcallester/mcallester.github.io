\input ../../SlidePreamble
\input ../../preamble

\begin{document}

{\Huge

  \centerline{\bf TTIC 31230, Fundamentals of Deep Learning}
  \bigskip
  \centerline{David McAllester, Autumn 2020}
  \vfill
  \vfill
  \centerline{\bf Loopy Belief Propagation (Loopy BP)}
\vfill
\vfill
\vfill

\slide{Loopy Belief Propagation (Loopy BP)}

We design an algorithm that is correct for tree graphs and use it on non-tree (loopy) graphs.

\anaslide{Belief Propagation on Trees}

\centerline{\includegraphics[height=1.5in]{\images/Tree}}

\vfill
Belief Propagation is a message passing procedure (actually dynamic programming).

\vfill
For each edge $\{n,m\}$ and possible value $y$ for node $n$ we define the message {\color{red} $Z_{m \rightarrow n}[y]$}
from $m$ to $n$ to be  the partition function for the subtree attached to $n$ through $m$ and
with $\hat{\cal Y}[n]$ restricted to $y$.

\slide{Dynamic Programming Computes the Messages}

\centerline{\includegraphics[height=2.0in]{\images/Tree}}

\vfill
\begin{eqnarray*}
  Z_{m\rightarrow n}[y] & = & \sum_{y'}  e^{s^N[m,y'] + s^E[\tuple{m,n},y',y]}
    \left(\prod_{k \in N(m),\;k \not = n}\;Z_{k\rightarrow m}[y']\right)
\end{eqnarray*}

\slide{Loopy BP}

In a Loopy Graph we can initializing all message $Z_{n \rightarrow m}[y] = 1$ and then repeating (until convergence) the updates
\vfill
\begin{eqnarray*}
  \tilde{Z}_{m \rightarrow n}[y] & = & \frac{1}{Z_{m \rightarrow n}}\;Z_{m \rightarrow n}[y] \;\;\;\;\;Z_{m \rightarrow n} = \sum_{y} Z_{m \rightarrow n}[y] \\
  \\
  \\
  Z_{m\rightarrow n}[y] & = & \sum_{y'}  e^{s^N[m,y'] + s^E[m,n,y',y]}
    \left(\prod_{k \in N(m),\;k \not = n}\;\tilde{Z}_{k\rightarrow m}[y']\right)
\end{eqnarray*}

\anaslide{Computing Node Marginals from Messages}

\centerline{\includegraphics[height=1.5in]{\images/Tree}}

\begin{eqnarray*}
Z^N(y) & = & \sum_{\hat{\cal Y}:\; \hat{\cal Y}[n] = y} \;e^{s(\hat{\cal Y})} \\
\\
& = & e^{s^N[y]} \left(\prod_{m\in N(n)} Z_{m \rightarrow n}[y]\right) \\
\\
{\color{red} P^N(y)} & = & Z^N(y)/Z,\;\;\;\;\; Z = \sum_{y}\;Z^N(y)
\end{eqnarray*}


\anaslide{Computing Edge Marginals from Messages}

\begin{eqnarray*}
Z_{n,m}(y,y') & \doteq & \sum_{\hat{\cal Y}:\; \hat{\cal Y}[n] = c,\;\hat{\cal Y}[m] = y'} \;e^{s(\hat{\cal Y})} \\
\\
& = & e^{s^N[n,y] + s^N[m,y'] +s^E[n,m,y,y']} \\
& & \prod_{m\in N(n),\;k \not = m} Z_{m \rightarrow n}[y] \\
& & \prod_{m\in N(m),\;k \not = n} Z_{m \rightarrow n}[y'] \\
\\
{\color{red} P_{n,m}(y,y')} & = & Z_{n,m}(y,y')/Z\;\;\;Z = \sum_{y,y'}\;Z_{n,m}(y,y')
\end{eqnarray*}

\slide{END}

}

\end{document}
