\documentclass{article}
\input ../preamble
\parindent = 0em

\newcommand{\solution}[1]{}
%\newcommand{\solution}[1]{\bigskip {\color{red} {\bf Solution}: #1}}

\begin{document}

\centerline{\bf TTIC 31230 Fundamentals of Deep Learning}
\bigskip
\centerline{\bf Regularization and  Generalization Problems}

\bigskip
\bigskip

{\bf Problem 1. The Stationary Points for $L_2$ Regularization.} Consider the regularized objective
$$\Phi^* = \argmin_\Phi \;E_{(x,y) \sim \mathrm{Train}}\;\left({\cal L}(\Phi,x,y) + \frac{1}{2N_{\mathrm{train}}\sigma^2}||\Phi||^2\right)$$
By setting the gradient of the objective to zero, solve for $\Phi$ as a function of the average gradient $g$ defined by
$$g = E_{\tuple{x,y}\sim \mathrm{Train}} \nabla \Phi {\cal L}(\Phi,x,y).$$

\solution{
  \begin{eqnarray*}
    & & \nabla_\Phi E_{(x,y) \sim \mathrm{Train}}\;{\cal L}(\Phi,x,y) + \frac{1}{2N_{\mathrm{train}}\sigma^2}||\Phi||^2 \\
    \\
    & = & \left(E_{(x,y) \sim \mathrm{Train}}\;\nabla_\Phi {\cal L}(\Phi,x,y)\right) + \frac{1}{N_{\mathrm{train}}\sigma^2}\Phi \\
    \\
    & = & g + \frac{1}{N_{\mathrm{train}}\sigma^2}\Phi \;\;= 0 \\
    \\
    \Phi & = & - N_{\mathrm{train}}\sigma^2g
  \end{eqnarray*}

  \medskip
  Note that a larger sample size justifies having a larger norm for the parameter vector.
}


\bigskip
{\bf Problem 4. (25 pts)} This problem is on PAC-Bayes bounds for classifiers built on CLIP using {\bf prompt engineering}.  CLIP is a joint probability model on images
and English descriptions (image captions).  Clip is trained on a large corpus of captioned images drawn from the web and defines a probability distribution over captions $c$ given an image $x$.
We can use CLIP for image classification (as in ImageNet) using ``prompt engineering''.  A ``prompt'' is caption specific to an image label.  For example the caption ``this is an image of a cat'' for the label ``cat'' or ``this is an image of a dog''
for the label ``dog''. For each image class $y$ we have a prompt (hypothetical caption) $c(y)$.
We can then label an image $x$ with class $\hat{y}$ using the rule
$$\hat{y}(x) = \argmax_y \;P_{\mathrm{CLIP}}(c(y)|x)$$
Suppose that we search (somehow) over the captions $c(y_1),\ldots,c(y_n)$ assigned to the $n$
image classes $y_1,\ldots,y_n$ to find a set of captions minimizing the error rate (0-1 loss) on a set of $N$ labeled training images.  Let $\hat{\cal L}$ be the error rate on the training data.
Also suppose that CLIP assigns a prior probability $P_{\mathrm{CLIP}}(c)$ to any caption $c$ independent of any image.  Consider the PAC-Bayes bound on generalization loss for predictive rule $h$
where the bound is guaranteed to hold for all $h$ with probability at least $1-\delta$.
$${\cal L}(h) \leq \frac{10}{9}\left(\hat{{\cal L}}(h) + \frac{5\lmax}{N_\mathrm{Train}}\left(- \ln P(h) +\ln\frac{1}{\delta}\right)\right)$$
Apply this rule to the CLIP image classifier using CLIP's ``prior probability'' on the caption space.

\solution{
  $${\cal L}(h) \leq \frac{10}{9}\left(\hat{{\cal L}}(h) + \frac{5}{N}\left(\left(\sum_y - \ln P_{\mathrm{CLIP}}(c(y))\right) +\ln\frac{1}{\delta}\right)\right)$$

  I am not proposing that searching over all captions is a good idea.  Some narrower prior is called for.
}

\end{document}
