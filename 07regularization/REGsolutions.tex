\documentclass{article}
\input ../preamble
\parindent = 0em

%\newcommand{\solution}[1]{}
\newcommand{\solution}[1]{\bigskip {\color{red} {\bf Solution}: #1}}

\begin{document}

\centerline{\bf TTIC 31230 Fundamentals of Deep Learning}
\bigskip
\centerline{\bf Regularization and  Generalization Problems}

\bigskip
\bigskip

{\bf Problem 1. The Stationary Points for $L_2$ Regularization.} Consider the regularized objective
$$\Phi^* = \argmin_\Phi \;E_{(x,y) \sim \mathrm{Train}}\;\left({\cal L}(\Phi,x,y) + \frac{1}{2N_{\mathrm{train}}\sigma^2}||\Phi||^2\right)$$
By setting the gradient of the objective to zero, solve for $\Phi$ as a function of the average gradient $g$ defined by
$$g = E_{\tuple{x,y}\sim \mathrm{Train}} \nabla \Phi {\cal L}(\Phi,x,y).$$

\solution{
  \begin{eqnarray*}
    & & \nabla_\Phi E_{(x,y) \sim \mathrm{Train}}\;{\cal L}(\Phi,x,y) + \frac{1}{2N_{\mathrm{train}}\sigma^2}||\Phi||^2 \\
    \\
    & = & \left(E_{(x,y) \sim \mathrm{Train}}\;\nabla_\Phi {\cal L}(\Phi,x,y)\right) + \frac{1}{N_{\mathrm{train}}\sigma^2}\Phi \\
    \\
    & = & g + \frac{1}{N_{\mathrm{train}}\sigma^2}\Phi \;\;= 0 \\
    \\
    \Phi & = & - N_{\mathrm{train}}\sigma^2g
  \end{eqnarray*}

  \medskip
  Note that a larger sample size justifies having a larger norm for the parameter vector.
}


\end{document}
